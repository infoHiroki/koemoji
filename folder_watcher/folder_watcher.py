#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‚’ç›£è¦–ã—ã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¿½åŠ ã•ã‚ŒãŸã¨ãã«ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import os
import time
import logging
import threading
import hashlib
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Callable, Set
import queue

try:
    from watchdog.observers import Observer
    from watchdog.events import FileSystemEventHandler, FileCreatedEvent
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: watchdogãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("pip install watchdog ã‚’å®Ÿè¡Œã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    exit(1)

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("folder_watcher.log", encoding="utf-8")
    ]
)
logger = logging.getLogger("folder_watcher")


class MediaFileHandler(FileSystemEventHandler):
    """ç›£è¦–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, supported_extensions: List[str], file_queue: queue.Queue, processed_files: Set[str]):
        """åˆæœŸåŒ–
        
        Args:
            supported_extensions: ç›£è¦–å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãƒªã‚¹ãƒˆ
            file_queue: å‡¦ç†å¾…ã¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ¥ãƒ¼
            processed_files: å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚»ãƒƒãƒˆ
        """
        self.supported_extensions = supported_extensions
        self.file_queue = file_queue
        self.processed_files = processed_files
    
    def on_created(self, event):
        """ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†"""
        if not event.is_directory:
            file_path = event.src_path
            ext = os.path.splitext(file_path)[-1].lower()
            
            if ext in self.supported_extensions:
                logger.info(f"æ–°ã—ã„ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: {file_path}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¯èƒ½ã«ãªã‚‹ã¾ã§å°‘ã—å¾…æ©Ÿï¼ˆä»–ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚ˆã‚‹æ›¸ãè¾¼ã¿å®Œäº†å¾…ã¡ï¼‰
                time.sleep(1)
                
                # å‡¦ç†æ¸ˆã¿ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                file_hash = get_file_hash(file_path)
                if file_path in self.processed_files or file_hash in self.processed_files:
                    logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™: {file_path}")
                    return
                
                self.file_queue.put(file_path)


class FolderWatcher:
    """ãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆæœŸåŒ–
        
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ï¼‰
        """
        self.config_path = config_path or "folder_watcher_config.json"
        self.config = self.load_config()
        
        self.file_queue = queue.Queue()
        self.processed_files = set()
        self.observer = None
        self.processing_thread = None
        self.should_stop = False
        self.callback_function = None
    
    def load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                config_data = json.load(f)
                return config_data
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”ã™
            return {
                "input_directory": "",
                "supported_extensions": [
                    ".mp3", ".mp4", ".wav", ".m4a", ".avi", ".mov", ".wmv", ".flac"
                ],
                "processed_files": {}
            }
    
    def save_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
        try:
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(self.config, f, ensure_ascii=False, indent=4)
            logger.info("è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def mark_file_as_processed(self, file_path: str, result_info: Optional[Dict[str, Any]] = None):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
        
        Args:
            file_path: å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            result_info: å‡¦ç†çµæœæƒ…å ±ï¼ˆçœç•¥å¯ï¼‰
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
        file_hash = get_file_hash(file_path)
        
        # å‡¦ç†æƒ…å ±ã‚’è¨˜éŒ²
        processed_info = {
            "processed_at": datetime.now().isoformat(),
        }
        
        # çµæœæƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
        if result_info:
            processed_info.update(result_info)
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
        if "processed_files" not in self.config:
            self.config["processed_files"] = {}
        
        # ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ã‚­ãƒ¼ã¨ã—ã¦ä¿å­˜
        self.config["processed_files"][file_hash] = processed_info
        self.processed_files.add(file_hash)
        
        # è¨­å®šã‚’ä¿å­˜
        self.save_config()
        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†æ¸ˆã¿ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸ: {file_path}")
    
    def set_callback(self, callback_function: Callable[[str], None]):
        """ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š
        
        Args:
            callback_function: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å¼•æ•°ã«å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        """
        self.callback_function = callback_function
    
    def process_file_queue(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ¥ãƒ¼ã‚’å‡¦ç†"""
        logger.info("ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")
        
        while not self.should_stop:
            try:
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                try:
                    file_path = self.file_queue.get(timeout=1)
                except queue.Empty:
                    continue
                
                # å‡¦ç†æ¸ˆã¿ã‹ã©ã†ã‹ã®å†ãƒã‚§ãƒƒã‚¯
                file_hash = get_file_hash(file_path)
                if file_path in self.processed_files or file_hash in self.processed_files:
                    logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™ï¼ˆã‚­ãƒ¥ãƒ¼å†…å†ãƒã‚§ãƒƒã‚¯ï¼‰: {file_path}")
                    self.file_queue.task_done()
                    continue
                
                # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’å®Ÿè¡Œ
                if self.callback_function:
                    try:
                        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {file_path}")
                        self.callback_function(file_path)
                        # æ³¨æ„: ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã®ä¸­ã§ mark_file_as_processed ã‚’å‘¼ã³å‡ºã™ã“ã¨ã‚’æ¨å¥¨
                    except Exception as e:
                        logger.error(f"ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                else:
                    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è‡ªå‹•çš„ã«å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
                    self.mark_file_as_processed(file_path)
                
                # ã‚­ãƒ¥ãƒ¼ã®ã‚¿ã‚¹ã‚¯å®Œäº†ã‚’é€šçŸ¥
                self.file_queue.task_done()
            
            except Exception as e:
                logger.exception(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                try:
                    self.file_queue.task_done()
                except:
                    pass
        
        logger.info("ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚")
    
    def start_file_watcher(self) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚’é–‹å§‹
        
        Returns:
            bool: ç›£è¦–é–‹å§‹ã«æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        input_dir = self.config.get("input_directory", "")
        
        if not input_dir:
            logger.error("å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return False
        
        if not os.path.exists(input_dir):
            try:
                os.makedirs(input_dir, exist_ok=True)
                logger.info(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {input_dir}")
            except Exception as e:
                logger.error(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return False
        
        try:
            supported_extensions = self.config.get("supported_extensions", [])
            # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚»ãƒƒãƒˆã‚’æ›´æ–°
            self.processed_files = set(self.config.get("processed_files", {}).keys())
            
            event_handler = MediaFileHandler(supported_extensions, self.file_queue, self.processed_files)
            self.observer = Observer()
            self.observer.schedule(event_handler, input_dir, recursive=False)
            self.observer.start()
            logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {input_dir}")
            return True
        
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return False
    
    def check_existing_files(self):
        """ç›£è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        input_dir = self.config.get("input_directory", "")
        if not input_dir or not os.path.exists(input_dir):
            return
        
        extensions = self.config.get("supported_extensions", [])
        count = 0
        processed_count = 0
        
        for file in os.listdir(input_dir):
            file_path = os.path.join(input_dir, file)
            if os.path.isfile(file_path):
                ext = os.path.splitext(file)[-1].lower()
                if ext in extensions:
                    # å‡¦ç†æ¸ˆã¿ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
                    file_hash = get_file_hash(file_path)
                    if file_path in self.processed_files or file_hash in self.processed_files:
                        processed_count += 1
                        continue
                        
                    self.file_queue.put(file_path)
                    count += 1
        
        if count > 0:
            logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æœªå‡¦ç†ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ« {count}å€‹ ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
        if processed_count > 0:
            logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å‡¦ç†æ¸ˆã¿ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ« {processed_count}å€‹ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
    
    def clean_old_processed_files(self, max_entries: int = 1000):
        """å¤ã„å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        
        Args:
            max_entries: ä¿æŒã™ã‚‹æœ€å¤§ã‚¨ãƒ³ãƒˆãƒªæ•°
        """
        processed_files = self.config.get("processed_files", {})
        if not processed_files:
            return
        
        # ã‚¨ãƒ³ãƒˆãƒªæ•°ãŒä¸Šé™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if len(processed_files) > max_entries:
            logger.info(f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™ (ç¾åœ¨: {len(processed_files)} ã‚¨ãƒ³ãƒˆãƒª)")
            
            # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
            sorted_entries = sorted(
                processed_files.items(),
                key=lambda x: x[1].get("processed_at", ""),
                reverse=True
            )
            
            # ä¸Šé™æ•°ã¾ã§å‰Šæ¸›
            self.config["processed_files"] = dict(sorted_entries[:max_entries])
            self.save_config()
            
            # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒãƒˆã‚’æ›´æ–°
            self.processed_files = set(self.config.get("processed_files", {}).keys())
            
            logger.info(f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ {len(processed_files)} ã‹ã‚‰ {len(self.config['processed_files'])} ã‚¨ãƒ³ãƒˆãƒªã«å‰Šæ¸›ã—ã¾ã—ãŸ")
    
    def start(self) -> bool:
        """ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹ã®é–‹å§‹
        
        Returns:
            bool: ç›£è¦–é–‹å§‹ã«æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self.clean_old_processed_files()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã®é–‹å§‹
        self.should_stop = False
        self.processing_thread = threading.Thread(target=self.process_file_queue, daemon=True)
        self.processing_thread.start()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã®é–‹å§‹
        if not self.start_file_watcher():
            self.stop()
            return False
        
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
        self.check_existing_files()
        
        logger.info("ğŸš€ ãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸã€‚")
        return True
    
    def stop(self):
        """ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹ã®åœæ­¢"""
        # åœæ­¢ãƒ•ãƒ©ã‚°ã®è¨­å®š
        self.should_stop = True
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã®åœæ­¢
        if self.observer:
            self.observer.stop()
            self.observer.join()
            self.observer = None
        
        # å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã®å¾…æ©Ÿ
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=5)
            self.processing_thread = None
        
        logger.info("ğŸ›‘ ãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸã€‚")
    
    def set_input_directory(self, directory: str) -> bool:
        """å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        
        Args:
            directory: è¨­å®šã™ã‚‹å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            
        Returns:
            bool: è¨­å®šã«æˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        if not os.path.exists(directory):
            try:
                os.makedirs(directory, exist_ok=True)
            except Exception as e:
                logger.error(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return False
        
        self.config["input_directory"] = directory
        self.save_config()
        logger.info(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¾ã—ãŸ: {directory}")
        return True
    
    def set_supported_extensions(self, extensions: List[str]):
        """ç›£è¦–å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’è¨­å®š
        
        Args:
            extensions: æ‹¡å¼µå­ã®ãƒªã‚¹ãƒˆ
        """
        self.config["supported_extensions"] = extensions
        self.save_config()
        logger.info(f"å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’è¨­å®šã—ã¾ã—ãŸ: {extensions}")


def get_file_hash(file_path: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨ãƒ‘ã‚¹ã®çµ„ã¿åˆã‚ã›ï¼‰
    
    Args:
        file_path: ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸãƒãƒƒã‚·ãƒ¥å€¤
    """
    # é«˜é€ŸåŒ–ã®ãŸã‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨ãƒ‘ã‚¹ã®çµ„ã¿åˆã‚ã›ã‚’ãƒãƒƒã‚·ãƒ¥
    try:
        file_size = os.path.getsize(file_path)
        hash_input = f"{file_path}:{file_size}"
        return hashlib.md5(hash_input.encode()).hexdigest()
    except Exception as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ‘ã‚¹ã®ã¿ã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ
        return hashlib.md5(file_path.encode()).hexdigest()


# ä½¿ç”¨ã‚µãƒ³ãƒ—ãƒ«
if __name__ == "__main__":
    def process_file(file_path: str):
        """ã‚µãƒ³ãƒ—ãƒ«ã®å‡¦ç†é–¢æ•°"""
        print(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_path} ã‚’å‡¦ç†ã—ã¾ã™...")
        # ã“ã“ã§å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’è¡Œã†
        
        # å‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
        watcher.mark_file_as_processed(file_path, {"result": "success"})
    
    # ãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
    watcher = FolderWatcher()
    
    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
    input_dir = input("ç›£è¦–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
    watcher.set_input_directory(input_dir)
    
    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã®è¨­å®š
    watcher.set_callback(process_file)
    
    # ç›£è¦–é–‹å§‹
    if watcher.start():
        print("ãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚Ctrl+Cã§çµ‚äº†ã§ãã¾ã™ã€‚")
        
        try:
            # ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ç¶­æŒ
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nãƒ•ã‚©ãƒ«ãƒ€ç›£è¦–ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
            watcher.stop()
            print("ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")